{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT文本分類-0(更新).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henry-del/assignment2/blob/master/BERT%E6%96%87%E6%9C%AC%E5%88%86%E9%A1%9E_0(%E6%9B%B4%E6%96%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtY0jx_5YUBg",
        "outputId": "bef0bb66-7ed4-4da7-fdaf-16ed42116e0b"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3xiPIwYXEq"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OnyyqVGBcd1D",
        "outputId": "c16421bb-14ac-4d86-93c3-cd7a8728fe33"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a11b4804-d2b2-407b-9c38-4abe0a76728f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a11b4804-d2b2-407b-9c38-4abe0a76728f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 訓練模型用評分結果-01+02+03.xlsx to 訓練模型用評分結果-01+02+03 (4).xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TIQ9djjev7q"
      },
      "source": [
        "data=pd.read_excel(\"訓練模型用評分結果-01+02+03.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvXFaNIkZ3aQ",
        "outputId": "d3e2c46e-69e9-468b-ab6b-cc85a952c31a"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 543 entries, 0 to 542\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   1            543 non-null    int64 \n",
            " 1   打籃球          543 non-null    object\n",
            " 2   因為它的圖中有打籃球   543 non-null    object\n",
            " 3   晴日與雨天        543 non-null    object\n",
            " 4   因為圖中有有晴天和雨天  543 non-null    object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 21.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55raPgcg1WGZ"
      },
      "source": [
        "data.columns=['score','story1','story2','story3','story4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "98-CjaVksCLI",
        "outputId": "948cccd9-31ff-4e7c-e3d3-824595e8ec03"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>story1</th>\n",
              "      <th>story2</th>\n",
              "      <th>story3</th>\n",
              "      <th>story4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>去打籃球</td>\n",
              "      <td>因為它的圖中有打籃球</td>\n",
              "      <td>今天天氣</td>\n",
              "      <td>因為圖中有天氣，是雨天和晴天</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>打籃球趣</td>\n",
              "      <td>他們去打來球,打到一半的時候,突然下起噢。</td>\n",
              "      <td>去打籃球</td>\n",
              "      <td>他們</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>打籃球趣</td>\n",
              "      <td>他們去打籃球,打到一半的時候,突然下雨又打雷了。</td>\n",
              "      <td>去打籃球</td>\n",
              "      <td>,他</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>up的籃球比賽.</td>\n",
              "      <td>第一張是陰天的圖案,第二張有人在打籃球,但突然下雨了\\n所以這場比賽沒比完就結束了</td>\n",
              "      <td>未作答</td>\n",
              "      <td>未作答</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>下雨的時候</td>\n",
              "      <td>下雨的時候，不能打籃球。</td>\n",
              "      <td>沒有好天氣</td>\n",
              "      <td>原ㄌ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>1</td>\n",
              "      <td>天氣</td>\n",
              "      <td>看到有兩個有天氣的圖片</td>\n",
              "      <td>打籃球</td>\n",
              "      <td>看到有兩個人在打籃球</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>1</td>\n",
              "      <td>作怪的天氣</td>\n",
              "      <td>原本天氣晴朗和朋友在打球\\n但是突然烏雲密布</td>\n",
              "      <td>籃球生涯</td>\n",
              "      <td>一開始打籃球會很高興\\n但是之後有低潮</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>1</td>\n",
              "      <td>一起來打球</td>\n",
              "      <td>看到兩個小孩在籃球場打球</td>\n",
              "      <td>下雨了</td>\n",
              "      <td>原本是晴天,兩個人去打球,突然下起了大雨</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>1</td>\n",
              "      <td>周末</td>\n",
              "      <td>我跟朋友在打球然後下雨了</td>\n",
              "      <td>下雨</td>\n",
              "      <td>我們在打球時下雨了我們沒帶傘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>2</td>\n",
              "      <td>悲劇</td>\n",
              "      <td>都快要下雨了，兩個剛放假的屁孩不怕死，硬要出門打球。結果，在屁孩Ａ上籃的那瞬間，打雷了！！！</td>\n",
              "      <td>雷神衰爾</td>\n",
              "      <td>雷神衰爾脾氣大，就喜歡躲在大太陽的雲後，對著愛打籃球的熱血少年，揮出他雷神之槌，爆破所有人的籃球。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>543 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     score    story1  ... story3                                             story4\n",
              "0        1      去打籃球  ...   今天天氣                                     因為圖中有天氣，是雨天和晴天\n",
              "1        1      打籃球趣  ...   去打籃球                                                 他們\n",
              "2        1      打籃球趣  ...   去打籃球                                                 ,他\n",
              "3        0  up的籃球比賽.  ...    未作答                                                未作答\n",
              "4        0     下雨的時候  ...  沒有好天氣                                                 原ㄌ\n",
              "..     ...       ...  ...    ...                                                ...\n",
              "538      1        天氣  ...    打籃球                                         看到有兩個人在打籃球\n",
              "539      1     作怪的天氣  ...   籃球生涯                                一開始打籃球會很高興\\n但是之後有低潮\n",
              "540      1     一起來打球  ...    下雨了                               原本是晴天,兩個人去打球,突然下起了大雨\n",
              "541      1        周末  ...     下雨                                     我們在打球時下雨了我們沒帶傘\n",
              "542      2        悲劇  ...   雷神衰爾  雷神衰爾脾氣大，就喜歡躲在大太陽的雲後，對著愛打籃球的熱血少年，揮出他雷神之槌，爆破所有人的籃球。\n",
              "\n",
              "[543 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T--Zor1164D"
      },
      "source": [
        "data['story']=data['story1']+data['story2']+data['story3']+data['story4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD2EZwFa2Xh7"
      },
      "source": [
        "data=data.drop(['story1','story2','story3','story4'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb86GXP_ew0Q"
      },
      "source": [
        "data['story']=data['story'].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMP3zat2l2JC",
        "outputId": "f022f6a0-f599-4bf3-f0e6-7339b00f841d"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRAwCsv8r676",
        "outputId": "0438f976-f2ae-4013-8b72-aa49fc55ddc7"
      },
      "source": [
        "data.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "score    False\n",
              "story    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp7YNZhsrSxi",
        "outputId": "a616af75-3d72-4b5a-b505-a74064b1cce6"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(543, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU1Wk9knrcP4",
        "outputId": "a4871ad5-7647-4397-8c0f-a053abfea414"
      },
      "source": [
        "data.columns.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['score', 'story'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MthTVpuDc0ZZ"
      },
      "source": [
        "data['score']=tf.cast(data['score'], tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-phS0O3Pc6aJ",
        "outputId": "d653e4a1-72a1-4ace-f226-edec88c97400"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "score    float32\n",
              "story     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhu-koa1LTLj"
      },
      "source": [
        "#def tran_cat_to_num(data):\n",
        "#    if data['score'] == 1:\n",
        "#        return 1.0\n",
        "#    elif data['score'] == 0:\n",
        "#        return 0.0\n",
        "#    else:\n",
        "#      return 1.0\n",
        "#data['score']=data.apply(tran_cat_to_num,axis=1)\n",
        "#data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0wfYzWWusML"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test= train_test_split(data,test_size=0.4,stratify=np.array(data['score']))\n",
        "#valid,test= train_test_split(test,test_size=0.5,stratify=np.array(test['score']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS-i_rcG9fku",
        "outputId": "3fe9b186-843f-43f5-916c-37c6cea206b0"
      },
      "source": [
        "data['score'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    381\n",
              "2.0     82\n",
              "0.0     80\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UobfvAL_9oW",
        "outputId": "28ccb822-958c-4d04-9ab1-46d92e78bd8b"
      },
      "source": [
        "train['score'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    228\n",
              "2.0     49\n",
              "0.0     48\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1rM6abi-hEy",
        "outputId": "63baa304-4962-4621-b40a-df0e43fa63e7"
      },
      "source": [
        "test['score'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    153\n",
              "2.0     33\n",
              "0.0     32\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FooxAmWuA__y"
      },
      "source": [
        "#valid['score'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SotoMxRnd_nk",
        "outputId": "30c9daf2-454e-42bc-d14d-b40250c9c9d6"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HySLjqShP4Yv"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n",
        "# 取得此預訓練模型所使用的 tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTsceTi_fK7l",
        "outputId": "69918869-5c1a-4b8f-f32b-8cfa1de3ea1f"
      },
      "source": [
        "max_length_test = 80\n",
        "test_sentence = '4455444456444400128'\n",
        "test_sentence_with_special_tokens = '[CLS]' + test_sentence + '[SEP]'\n",
        "tokenized = tokenizer.tokenize(test_sentence_with_special_tokens)\n",
        "print('tokenized', tokenized)\n",
        "\n",
        "# convert tokens to ids in WordPiece\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
        "  \n",
        "# precalculation of pad length, so that we can reuse it later on\n",
        "padding_length = max_length_test - len(input_ids)\n",
        "\n",
        "# map tokens to WordPiece dictionary and add pad token for those text shorter than our max length\n",
        "input_ids = input_ids + ([0] * padding_length)\n",
        "\n",
        "# attention should focus just on sequence with non padded tokens\n",
        "attention_mask = [1] * len(input_ids)\n",
        "\n",
        "# do not focus attention on padded tokens\n",
        "attention_mask = attention_mask + ([0] * padding_length)\n",
        "\n",
        "# token types, needed for example for question answering, for our purpose we will just set 0 as we have just one sequence\n",
        "token_type_ids = [0] * max_length_test\n",
        "bert_input = {\n",
        "    \"token_ids\": input_ids,\n",
        "    \"token_type_ids\": token_type_ids,\n",
        "    \"attention_mask\": attention_mask\n",
        "} \n",
        "print(bert_input)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized ['[CLS]', '445', '##54', '##44', '##45', '##64', '##44', '##400', '##12', '##8', '[SEP]']\n",
            "{'token_ids': [101, 12834, 9488, 9292, 9039, 9165, 9292, 10765, 8455, 8156, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nxMO92vf6WB",
        "outputId": "5e5adb35-1783-4c37-ae5a-7e25ce07b400"
      },
      "source": [
        "bert_input = tokenizer.encode_plus(\n",
        "                        test_sentence,                      \n",
        "                        add_special_tokens = True, # add [CLS], [SEP]\n",
        "                        max_length = max_length_test, # max length of the text that can go to BERT\n",
        "                        pad_to_max_length = True, # add [PAD] tokens\n",
        "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )\n",
        "print('encoded', bert_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "encoded {'input_ids': [101, 12834, 9488, 9292, 9039, 9165, 9292, 10765, 8455, 8156, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoIctVhSjbl5"
      },
      "source": [
        "def convert_example_to_feature(review):\n",
        "  max_length=80\n",
        "  # combine step for tokenization, WordPiece vector mapping, adding special tokens as well as truncating reviews longer than the max length\n",
        "  \n",
        "  return tokenizer.encode_plus(review, \n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = max_length, # max length of the text that can go to BERT\n",
        "                pad_to_max_length = True, # add [PAD] tokens\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k4LKODljcU5"
      },
      "source": [
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvTXykF1qm5x"
      },
      "source": [
        "def encode_examples(data):\n",
        "  \n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = []    \n",
        "  for story,score in zip(list(data['story']),list(data['score'])):\n",
        "    \n",
        "    bert_input = convert_example_to_feature(story)\n",
        "  \n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "    label_list.append([score])\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59u8AY1r5cWD"
      },
      "source": [
        "batch_size=80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0RmUrKxumoU",
        "outputId": "e582829d-cad8-47bc-f3af-2bad5a0e69c4"
      },
      "source": [
        "# train dataset\n",
        "ds_train_encoded = encode_examples(train).shuffle(10).batch(batch_size)\n",
        "\n",
        "# test dataset\n",
        "ds_test_encoded = encode_examples(test).batch(batch_size)\n",
        "\n",
        "#valid dataset\n",
        "#ds_val_encoded = encode_examples(valid).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU4ENQoEMq4o"
      },
      "source": [
        "#from transformers import TFBertForSequenceClassification,BertTokenizer\n",
        "#import tensorflow as tf\n",
        "\n",
        "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
        "#learning_rate =5e-6\n",
        "\n",
        "# we will do just 1 epoch for illustration, though multiple epochs might be better as long as we will not overfit the model\n",
        "#number_of_epochs = 15\n",
        "\n",
        "\n",
        "# model initialization\n",
        "###model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")\n",
        "#model = BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")\n",
        "#model = TFBertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=3)\n",
        "#optimizer =  tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "#callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "#loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "# labels_dict : {ind_label: count_label}\n",
        "# mu : parameter to tune \n",
        "\n",
        "\n",
        "# random labels_dict\n",
        "#labels_dict = {0:49,1:76,2:11}\n",
        "\n",
        "#class_weight=create_class_weight(labels_dict)\n",
        "#fit model\n",
        "#bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_val_encoded)\n",
        "\n",
        "# evaluate test set\n",
        "#model.evaluate(ds_test_encoded)\n",
        "\n",
        "\n",
        "\n",
        "# choosing Adam optimizer\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "#model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCTbkTsaBaTX",
        "outputId": "a3b5eac9-9efc-43b8-b779-ea9b2783c3cf"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import model_selection\n",
        "from transformers import TFBertForSequenceClassification,BertTokenizer\n",
        "import tensorflow as tf\n",
        "# data sample\n",
        "# prepare cross validation\n",
        "learning_rate =2e-5\n",
        "number_of_epochs =8\n",
        "metric_accuracy=[]\n",
        "metric_loss=[]\n",
        "predict=[]\n",
        "actual=[]\n",
        "X,y=data['story'],data['score']\n",
        "kf = KFold(n_splits=10)\n",
        "kf.get_n_splits(X)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  X_train,y_train = X_train.to_frame(),y_train.to_frame() \n",
        "  X_test,y_test = X_test.to_frame(),y_test.to_frame() \n",
        "  train= pd.DataFrame(X_train,columns=['story'])\n",
        "  train= pd.concat([train,pd.DataFrame(y_train,columns=['score'])],axis=1)\n",
        "  test= pd.DataFrame(X_test,columns=['story'])\n",
        "  test= pd.concat([test,pd.DataFrame(y_test,columns=['score'])], axis=1)\n",
        "  batch_size=64\n",
        "  ds_train_encoded = encode_examples(train).shuffle(10).batch(batch_size)\n",
        "  ds_test_encoded = encode_examples(test).batch(batch_size)\n",
        "  model = TFBertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=3)\n",
        "  optimizer =  tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "  bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_train_encoded)\n",
        "  loss,accuracy=model.evaluate(ds_test_encoded)\n",
        "  metric_accuracy.append(accuracy)\n",
        "  metric_loss.append(loss)\n",
        "  A=tf.nn.softmax(model.predict(ds_test_encoded)[0])\n",
        "  B=np.argmax(A,1)\n",
        "  predict.append(B)\n",
        "  actual.append(pd.to_numeric(y_test['score']))\n",
        "print(\"results\",metric_accuracy)\n",
        "print(f\"Mean-Precision: {sum(metric_accuracy) / len(metric_accuracy)}\")    \n",
        "print(\"results\",metric_loss)\n",
        "print(f\"Mean-loss: {sum(metric_loss) / len(metric_loss)}\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8983 - accuracy: 0.6325WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 34s 1s/step - loss: 0.8887 - accuracy: 0.6403 - val_loss: 0.5531 - val_accuracy: 0.8238\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.5149 - accuracy: 0.8462 - val_loss: 0.4910 - val_accuracy: 0.8258\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4641 - accuracy: 0.8459 - val_loss: 0.4163 - val_accuracy: 0.8914\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3953 - accuracy: 0.8682 - val_loss: 0.2956 - val_accuracy: 0.8811\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3055 - accuracy: 0.8905 - val_loss: 0.2144 - val_accuracy: 0.9529\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2540 - accuracy: 0.9196 - val_loss: 0.2069 - val_accuracy: 0.9734\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2170 - accuracy: 0.9375 - val_loss: 0.1304 - val_accuracy: 0.9693\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1499 - accuracy: 0.9666 - val_loss: 0.0897 - val_accuracy: 0.9877\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5387 - accuracy: 0.8000\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f592e6050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8450 - accuracy: 0.6541WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 33s 2s/step - loss: 0.8355 - accuracy: 0.6611 - val_loss: 0.5353 - val_accuracy: 0.8176\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.5062 - accuracy: 0.8294 - val_loss: 0.4061 - val_accuracy: 0.8893\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4047 - accuracy: 0.8508 - val_loss: 0.2814 - val_accuracy: 0.9426\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3388 - accuracy: 0.8909 - val_loss: 0.2199 - val_accuracy: 0.9590\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2546 - accuracy: 0.9311 - val_loss: 0.1538 - val_accuracy: 0.9693\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1740 - accuracy: 0.9629 - val_loss: 0.1135 - val_accuracy: 0.9816\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1275 - accuracy: 0.9812 - val_loss: 0.0917 - val_accuracy: 0.9795\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.0932 - accuracy: 0.9849 - val_loss: 0.0670 - val_accuracy: 0.9857\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.4185 - accuracy: 0.8364\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f92b8ca9c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0313 - accuracy: 0.4621WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 34s 2s/step - loss: 1.0154 - accuracy: 0.4779 - val_loss: 0.5847 - val_accuracy: 0.7992\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.5628 - accuracy: 0.8094 - val_loss: 0.4188 - val_accuracy: 0.8811\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4296 - accuracy: 0.8469 - val_loss: 0.4002 - val_accuracy: 0.8443\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3996 - accuracy: 0.8646 - val_loss: 0.2262 - val_accuracy: 0.9406\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2524 - accuracy: 0.9178 - val_loss: 0.1487 - val_accuracy: 0.9631\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3246 - accuracy: 0.8688 - val_loss: 0.1342 - val_accuracy: 0.9713\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1563 - accuracy: 0.9652 - val_loss: 0.1140 - val_accuracy: 0.9816\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1099 - accuracy: 0.9831 - val_loss: 0.0768 - val_accuracy: 0.9877\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.1251 - accuracy: 0.9636\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f672c1050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.7760 - accuracy: 0.7177WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 34s 2s/step - loss: 0.7670 - accuracy: 0.7232 - val_loss: 0.4477 - val_accuracy: 0.8384\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4508 - accuracy: 0.8584 - val_loss: 0.4576 - val_accuracy: 0.8384\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3740 - accuracy: 0.8644 - val_loss: 0.2767 - val_accuracy: 0.9284\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3091 - accuracy: 0.8936 - val_loss: 0.1959 - val_accuracy: 0.9468\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2411 - accuracy: 0.9168 - val_loss: 0.1490 - val_accuracy: 0.9652\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1585 - accuracy: 0.9640 - val_loss: 0.1209 - val_accuracy: 0.9796\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2335 - accuracy: 0.9217 - val_loss: 0.1017 - val_accuracy: 0.9816\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1074 - accuracy: 0.9753 - val_loss: 0.0775 - val_accuracy: 0.9857\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.7357 - accuracy: 0.7963\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f673854d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.6517WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 34s 2s/step - loss: 0.8372 - accuracy: 0.6595 - val_loss: 0.5501 - val_accuracy: 0.8344\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.5212 - accuracy: 0.8433 - val_loss: 0.4317 - val_accuracy: 0.8425\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4098 - accuracy: 0.8547 - val_loss: 0.3721 - val_accuracy: 0.8855\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3557 - accuracy: 0.8627 - val_loss: 0.3113 - val_accuracy: 0.9284\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2961 - accuracy: 0.9031 - val_loss: 0.2021 - val_accuracy: 0.9468\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2704 - accuracy: 0.9079 - val_loss: 0.1485 - val_accuracy: 0.9632\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1577 - accuracy: 0.9625 - val_loss: 0.0995 - val_accuracy: 0.9836\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1025 - accuracy: 0.9846 - val_loss: 0.0622 - val_accuracy: 0.9939\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.9271 - accuracy: 0.7593\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f932a42d9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.7018WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 33s 2s/step - loss: 0.8610 - accuracy: 0.7009 - val_loss: 0.6680 - val_accuracy: 0.6994\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.6349 - accuracy: 0.7383 - val_loss: 0.4868 - val_accuracy: 0.8139\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4794 - accuracy: 0.8358 - val_loss: 0.3829 - val_accuracy: 0.8957\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3754 - accuracy: 0.8785 - val_loss: 0.3575 - val_accuracy: 0.8691\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2924 - accuracy: 0.9126 - val_loss: 0.1956 - val_accuracy: 0.9571\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2959 - accuracy: 0.8829 - val_loss: 0.1437 - val_accuracy: 0.9755\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1527 - accuracy: 0.9715 - val_loss: 0.0915 - val_accuracy: 0.9836\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.0984 - accuracy: 0.9829 - val_loss: 0.0651 - val_accuracy: 0.9857\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.3850 - accuracy: 0.9074\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9257bc1170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0088 - accuracy: 0.4976WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 33s 2s/step - loss: 0.9980 - accuracy: 0.5107 - val_loss: 0.6251 - val_accuracy: 0.8139\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.5877 - accuracy: 0.8215 - val_loss: 0.4371 - val_accuracy: 0.8282\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4462 - accuracy: 0.8428 - val_loss: 0.3267 - val_accuracy: 0.9141\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3400 - accuracy: 0.8855 - val_loss: 0.2238 - val_accuracy: 0.9509\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2382 - accuracy: 0.9463 - val_loss: 0.1369 - val_accuracy: 0.9632\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2251 - accuracy: 0.9282 - val_loss: 0.0955 - val_accuracy: 0.9836\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2150 - accuracy: 0.9216 - val_loss: 0.1015 - val_accuracy: 0.9836\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1159 - accuracy: 0.9741 - val_loss: 0.0646 - val_accuracy: 0.9939\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.3836 - accuracy: 0.8704\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f626a8320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.5381WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 33s 2s/step - loss: 0.9813 - accuracy: 0.5505 - val_loss: 0.6842 - val_accuracy: 0.7546\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.6487 - accuracy: 0.7651 - val_loss: 0.4825 - val_accuracy: 0.8303\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4983 - accuracy: 0.8372 - val_loss: 0.3836 - val_accuracy: 0.8344\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3887 - accuracy: 0.8542 - val_loss: 0.3041 - val_accuracy: 0.9141\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3535 - accuracy: 0.8764 - val_loss: 0.2551 - val_accuracy: 0.9223\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3082 - accuracy: 0.8955 - val_loss: 0.1959 - val_accuracy: 0.9509\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2147 - accuracy: 0.9376 - val_loss: 0.1367 - val_accuracy: 0.9775\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1475 - accuracy: 0.9774 - val_loss: 0.1008 - val_accuracy: 0.9816\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.5115 - accuracy: 0.8704\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f6708e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.8771 - accuracy: 0.6445WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 32s 2s/step - loss: 0.8678 - accuracy: 0.6524 - val_loss: 0.5519 - val_accuracy: 0.8303\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.5225 - accuracy: 0.8447 - val_loss: 0.4343 - val_accuracy: 0.8875\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4176 - accuracy: 0.8661 - val_loss: 0.4084 - val_accuracy: 0.8896\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3534 - accuracy: 0.8817 - val_loss: 0.2664 - val_accuracy: 0.9182\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3295 - accuracy: 0.8661 - val_loss: 0.1904 - val_accuracy: 0.9571\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2199 - accuracy: 0.9491 - val_loss: 0.1463 - val_accuracy: 0.9714\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1549 - accuracy: 0.9691 - val_loss: 0.1143 - val_accuracy: 0.9775\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1221 - accuracy: 0.9753 - val_loss: 0.0928 - val_accuracy: 0.9816\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.5485 - accuracy: 0.7593\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f92549968c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.0782 - accuracy: 0.4373WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "8/8 [==============================] - 33s 2s/step - loss: 1.0623 - accuracy: 0.4544 - val_loss: 0.6205 - val_accuracy: 0.8139\n",
            "Epoch 2/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.5985 - accuracy: 0.8207 - val_loss: 0.4517 - val_accuracy: 0.8303\n",
            "Epoch 3/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.4562 - accuracy: 0.8450 - val_loss: 0.3524 - val_accuracy: 0.8814\n",
            "Epoch 4/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3665 - accuracy: 0.8627 - val_loss: 0.3078 - val_accuracy: 0.9141\n",
            "Epoch 5/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.3041 - accuracy: 0.8994 - val_loss: 0.1890 - val_accuracy: 0.9407\n",
            "Epoch 6/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.2851 - accuracy: 0.8956 - val_loss: 0.1283 - val_accuracy: 0.9755\n",
            "Epoch 7/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.1614 - accuracy: 0.9695 - val_loss: 0.0836 - val_accuracy: 0.9857\n",
            "Epoch 8/8\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.0951 - accuracy: 0.9869 - val_loss: 0.0565 - val_accuracy: 0.9898\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.3942 - accuracy: 0.8519\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f64775320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "results [0.800000011920929, 0.8363636136054993, 0.9636363387107849, 0.7962962985038757, 0.7592592835426331, 0.9074074029922485, 0.8703703880310059, 0.8703703880310059, 0.7592592835426331, 0.8518518805503845]\n",
            "Mean-Precision: 0.8414814889430999\n",
            "results [0.5387492775917053, 0.41849005222320557, 0.12505963444709778, 0.7357193827629089, 0.9271183609962463, 0.3850431740283966, 0.3836427628993988, 0.511498749256134, 0.5485493540763855, 0.3941682279109955]\n",
            "Mean-loss: 0.4968038976192474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npooqG4pOChj"
      },
      "source": [
        "predict_list=[]\n",
        "for i in range(len(predict)):\n",
        "  predict_list.extend(list(predict[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeleRSluzf1s"
      },
      "source": [
        "actual_list=[]\n",
        "for i in range(len(actual)):\n",
        "  actual_list.extend(list(actual[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPV7hwBfR-qH"
      },
      "source": [
        "#A=tf.nn.softmax(model.predict(ds_test_encoded)[0])\n",
        "#B=np.argmax(A,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEhk3IOFSGao"
      },
      "source": [
        "#B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSCXKntGY-o1"
      },
      "source": [
        "#tf.cast(test['score'], tf.int32).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b64FYKo2Wdmi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "345a3aba-b1a7-47d3-d201-b61f1c18533f"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {'y_Actual':  actual_list,\n",
        "        'y_Predicted': predict_list}\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "df\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biw5sMlC8WIA"
      },
      "source": [
        "#def focal_loss(gamma=2., alpha=4.):\n",
        "#\n",
        "#    gamma = float(gamma)\n",
        "#    alpha = float(alpha)\n",
        "#\n",
        "#    def focal_loss_fixed(y_true, y_pred):\n",
        "#        \"\"\"Focal loss for multi-classification\n",
        "#        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "#        Notice: y_pred is probability after softmax\n",
        "#        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "#        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "#        Focal Loss for Dense Object Detection\n",
        "#        https://arxiv.org/abs/1708.02002\n",
        "#\n",
        "#        Arguments:\n",
        "#            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "#            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "#\n",
        "#        Keyword Arguments:\n",
        "#            gamma {float} -- (default: {2.0})\n",
        "#            alpha {float} -- (default: {4.0})\n",
        "#\n",
        "#        Returns:\n",
        "#            [tensor] -- loss.\n",
        "#        \"\"\"\n",
        "#        epsilon = 1.e-9\n",
        "#        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "#        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "#\n",
        "#        model_out = tf.add(y_pred, epsilon)\n",
        "#        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "#        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "#        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "#        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "#        return tf.reduce_mean(reduced_fl)\n",
        "#    return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GHD7QnHH8Qr"
      },
      "source": [
        "#text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "#                       optimizer=\"adam\",\n",
        "#                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smydCRdnII2W"
      },
      "source": [
        "#class_weight = {0 : 18.27, 1: 1., 2:15.46}\n",
        "#text_model.fit(train_data, epochs=NB_EPOCHS,class_weight=class_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag9mIjIIL2by"
      },
      "source": [
        "#predict=text_model.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mry22XbB00Sb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}